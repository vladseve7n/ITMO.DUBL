# ITMO.DUBL
В данном репозитории хранится код проекта для реализации поиска похожих компаний по их названию.

Основная идея подхода заключается в том, чтобы найти эмбеддинги названий компаний, а также возможных кластеров названий, чтобы при поиске похожих компаний по расстоянию между эмбеддингами решить, присутсвуют ли в данных похожие названия компаний или нет

## Разведочный анализ данных
Разведочный анализ представлень [здесь](Exploratory_analysis.md)

## Генерация кластеров из тренировочного датасета
Для того, чтобы применить алгоритм поиска ближайшего кластера названий компаний для подхода с использованием эмбеддингов изображений был сформирован датасет кластеров, который находится [здесь](dataset/clusters.json)

Он представляет из себя json файл, где по тегу "clusters" находится список списков кластеров названий компаний:  

```json
{
  "clusters": [
    ["ALFAGOMMA INDUSTRIAL SPA", " Alfagomma"], 
    [" SO.F.TER. SPA", "Softer Us Inc."],
    ...,
  ]
}
```

Код генерации кластеров представлен в данном [файле](nooteboks/Cluster_generation.ipynb)  

## Проблемы в датасете
В датасете присутствуют пары не всех кластеров, пример:
В данных присутствуют следующие уникальные названия, которые по логике должны матчиться с друг другом
```
[' LANXESS Inc.', ' Lanxess AG', ' Lanxess Accounting GmbH', ' Lanxess Chemical (China) Co., Ltd.', ' Lanxess Hong Kong Limited', ' Lanxess International Trading (Shanghai) Co., Ltd.', ' Lanxess Manufacturing Netherlands B.V.', ' Lanxess Sas',]
```
Но в датасете этого не [происходит](nooteboks/Cluster_generation.ipynb):
```
name = ' LANXESS Inc.'
couples = train_ds[((train_ds['name_1'] == name) | (train_ds['name_2'] == name)) & (train_ds['is_duplicate'] == 1)]
print(len(couples)) # 0
```
![image](https://user-images.githubusercontent.com/75368806/197779985-101228da-1966-41f6-8a70-2acad9549172.png)
Еще один пример:
```
 ['BASF CENRTAL ASIA LLP', 'BASF Central Asia LLP'],
 
 ['Basf Quimica Colombiana S.A.', "Basf's Paper Chemicals (Huizhou) Co., Ltd.", 'Basf New Zealand Ltd.', 'Basf Bangladesh Ltd.', 'Basf Co., Ltd.', 'Basf Co., Ltd. Yeosu', 'Basf Mexicana S.A. De C.V.', 'Basf Corp.', 'Basf Pakistan (Private) Ltd.', 'Basf Construction Chemicals', 'Basf Auxiliary Chemicals', 'Basf Japan Ltd.', 'Basf Construction Chemicals Ua', 'Basf De Costa Rica Sociedad Anonima', 'Basf Peruana S.A.', 'Basf India Ltd.', 'Basf Pakistan Ltd.', 'Basf Corporation', 'Basf (China) Co., Ltd. Shanghai', 'Basf Colors & Effects Usa Llc', 'Basf Chile S A', 'Basf Turk Kimya San Ve Tic.Tld.Sti', 'Bdp International Basf Imp.', 'Basf India', 'Basf Turk Kimya San.Ve Tic Ltd.Sti', 'Basf Finlay Pvt., Ltd.', 'Basf Sa', 'Basf Turk Kimya San. Ve Tic.Sti', 'Basf Japan Ltd. 6 10 1 Roppongi', 'Basf Chile S.A.']
```
По логике эти два кластера должны быть совместны, но пары из двух названий замыкаются сами на себя:
![image](https://user-images.githubusercontent.com/75368806/197780787-0dfea324-c6c4-4e4d-be83-aefed4e77708.png)



## Подходы к векторизации текста
BugOfWords, TF-IDF, Word2Vec, [Doc2Vec](nooteboks/D2V_implementation.ipynb) и др. алгоритмы использующие внутри себя словарь, по которому происходит векторизация текста не очень подходят для данной задачи по следующим причинам:
- Есть вероятность словить ошибку OutOfDictionary, когда в запросе на поиск похожих компаний будет слово, которое не встречалось в исходном словаре при обучении;
- При добавлении новых названий компаний, векторы нужно будет персчитывать заново;
- Низкое качество векторизации, которое уступает нейросетевым подходам.

Использование [нейросетевых](nooteboks/USE_implementation.ipynb) подходов для векторизации текста:
- Универсальны, так как не используют словарь. Но универсальность не всегда хорошо складывается на точности в использования сети в определенном домене;
- Требуют больше ресурсов для векторзации текста, но при этом позволяют для каждого примера использовать один embedding, что позволяет единожды сделать обсчёт для всех семплов;

## Подсчет метрик для USE
В качестве метрики использовалось понятие успешности запроса.  
Так как мы предварительно распарсили датасет на кластеры, мы точно можем знать для какого названия присутствует кластер, а для каких названий в датасете кластера нет, следовательно можно считать:
- Запрос **успешным**, когда для названия компании у которой нет кластера - алгоритм не выдает ничего, а для компании у которой присутствует кластер в датасете выдает верный кластер, в котором это название есть;
- Запрос **неверным**, когда для названия компании у которой нет кластера - алгоритм предлагает кластер, а для компании у которой присутствует кластер - алгоритм предлагает кластер, в котором этого названия нет.

При использовании НС USE можно подбирать следующие параметры:
- Тип предпроцессинга (перевод к нижнему регистру, перевод к нижнему регистру + чистка, никакой);
- Усреднение embedding'ов кластера с помощью (медианны, среднего);
- Дистанцию между векторами считать по расстоянию (l1, l2);
- Threshold по которому определяется является ли название частью кластера;

Алгоритм по которому проводился перебор можно найти [здесь](use_metric_evaluating.py)  
Таблица со сводкой всех данных представленна [здесь](dataset/use_metric_evaluating_result.csv) в формате .csv

Топ 5 результатов из таблицы:

| implementation | preprocess  | mean_type | distance | threshold         | f1                | accuracy          |
|----------------|-------------|-----------|----------|-------------------|-------------------|-------------------|
| USE            | lower_clean | median    | l1       | 11.8766890631782  | 0.647272727272727 | 0.946141032759578 |
| USE            | lower_clean | median    | l1       | 11.5373550899445  | 0.646189735614308 | 0.949472515269295 |
| USE            | lower_clean | mean      | l2       | 0.685978468724699 | 0.644645340751043 | 0.943253747917824 |
| USE            | lower_clean | median    | l1       | 12.2160230364118  | 0.642094385118843 | 0.942309827873403 |
| USE            | lower_clean | mean      | l2       | 0.66792640375826  | 0.641579731743666 | 0.94658523042754  |

## Использование алгоритма
Для тестирвания работы алгоритма:
1. Установите зависимости:
```
pip install -r requirements.txt
```
2. Запустите основной файл:

```
python main.py
```
```
usage: main.py [-h] [-i {USE}] [-p {lower_clean,lower,none}] [-d {l1,l2}] [-m {median,mean}] [-t THRESHOLD]
```

### Пайплайн
1. Загрузка данных (датасет с кластерами, тренировочный датасет);
2. Обработка данных;
3. Создание эмбеддингов для каждого уникального названия компании;
4. Создание эмбеддингов для кластера;
5. Сравнить полученный эмбеддинг введенной компании с эмбеддингами кластерами и по порогу выдать наиближайший.

Если при обработке запросов:
- Кластер был найден, то искомый пример добавляется в кластер и происходит пересчёт эмбеддинга кластера;
- Кластен был не найден, то создается новый кластер с введенным примером.

### Скорость работы
На процессоре Intel(R) Core(TM) i7-10700K CPU @ 3.8GHz скорость обработки 1 запроса в среднем составляет 0.012 секунды. Генерация 1 эмбеддинга 0.002 секунды

### Рекомендуемые системные требования
Процессор  
Intel Xeon E3-1230 3.4 ГГц  
Память  
16 ГБ DDR4  

Если скорость получения эмбеддинга критичная, то можно увеличить её за счёт вычисления на GPU. В данном случае подойдет карта с 8 Гб на борту 

